name: Build, Scan & Deploy Docker to EC2 via ECR

on:
  push:
    branches: ["main"]

jobs:

  # ============================================================
  # MAIN PIPELINE: Build → Scan → Push → Deploy → Generate Reports
  # ============================================================
  deploy:
    runs-on: ubuntu-latest

    outputs:
      run_id: ${{ github.run_id }}

    steps:

      # ---------------------------------------------------------
      # CHECKOUT (Full history for TruffleHog)
      # ---------------------------------------------------------
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # ---------------------------------------------------------
      # BUILD (Maven)
      # ---------------------------------------------------------
      - name: Set up Java
        uses: actions/setup-java@v3
        with:
          java-version: "17"
          distribution: "temurin"

      - name: Build WAR using Maven
        run: mvn -B clean package --file pom.xml

      # ---------------------------------------------------------
      # TRUFFLEHOG (Secrets Scan)
      # ---------------------------------------------------------
      - name: Install TruffleHog
        run: |
          pip install trufflehog==2.2.1

      - name: Run TruffleHog Secrets Scan
        run: |
          trufflehog git file://.` --json > trufflehog-results.json

      # ---------------------------------------------------------
      # SONARCLOUD (SAST)
      # ---------------------------------------------------------
      - name: SonarCloud Scan
        uses: SonarSource/sonarcloud-github-action@v2
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
        with:
          projectBaseDir: .

      - name: Export SonarCloud Raw Report
        run: |
          echo '{"note": "SonarCloud results stored on cloud dashboard"}' > sonar-report.json

      # ---------------------------------------------------------
      # SNYK (SCA + SAST + Container Scan)
      # ---------------------------------------------------------
      - name: Install Snyk CLI
        uses: snyk/actions/setup@v1
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

      - name: Snyk SCA Scan
        run: snyk test --json --severity-threshold=high > snyk-sca.json
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

      - name: Snyk SAST Scan
        run: snyk code test --json --severity-threshold=high > snyk-sast.json
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

      - name: Build Docker Image for Snyk Scan
        run: docker build -t app:latest .

      - name: Snyk Container Scan
        run: snyk container test app:latest --json --severity-threshold=high > snyk-container.json
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}

      # ---------------------------------------------------------
      # PRISMA CLOUD — twistcli Container Scan
      # ---------------------------------------------------------
      - name: Download twistcli
        run: |
          curl -u "${{ secrets.PRISMA_ACCESS_KEY }}:${{ secrets.PRISMA_SECRET_KEY }}" \
            --output twistcli \
            "${{ secrets.PRISMA_CONSOLE_URL }}/api/v1/util/twistcli"
          chmod +x twistcli

      - name: Prisma Cloud Scan
        run: |
          ./twistcli images scan \
            --address ${{ secrets.PRISMA_CONSOLE_URL }} \
            --user ${{ secrets.PRISMA_ACCESS_KEY }} \
            --password ${{ secrets.PRISMA_SECRET_KEY }} \
            --output-file prisma-scan.json \
            app:latest

      # ---------------------------------------------------------
      # AWS LOGIN + PUSH TO ECR
      # ---------------------------------------------------------
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v1

      - name: Push Image to ECR
        run: |
          ECR_URL="${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com"
          IMAGE_NAME="${{ secrets.ECR_REPO_NAME }}"
          TAG="latest"

          docker tag app:latest $ECR_URL/$IMAGE_NAME:$TAG
          docker push $ECR_URL/$IMAGE_NAME:$TAG

      # ---------------------------------------------------------
      # DEPLOYMENT ON EC2 (Container Restart)
      # ---------------------------------------------------------
      - name: Deploy on EC2
        uses: appleboy/ssh-action@v0.1.7
        with:
          host: ${{ secrets.EC2_HOST }}
          username: ${{ secrets.EC2_USER }}
          key: ${{ secrets.EC2_SSH_KEY }}
          script: |
            ECR_URL="${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com"
            IMAGE_NAME="${{ secrets.ECR_REPO_NAME }}"
            TAG="latest"

            sudo docker pull $ECR_URL/$IMAGE_NAME:$TAG
            sudo docker stop app || true
            sudo docker rm app || true
            sudo docker run -d --name app -p 80:8080 $ECR_URL/$IMAGE_NAME:$TAG

      # ---------------------------------------------------------
      # OWASP ZAP BASELINE (DAST)
      # ---------------------------------------------------------
      - name: Run OWASP ZAP Baseline Scan
        uses: zaproxy/action-baseline@v0.10.0
        with:
          target: "http://${{ secrets.EC2_HOST }}"
          cmd_options: "-a"
        continue-on-error: true

      - name: Rename ZAP reports
        run: |
          mv report_html.html zap-report.html || true
          mv report_json.json zap-report.json || true
          mv report_md.md zap-report.md || true


  # ============================================================
  # LOG COLLECTION + UPLOAD TO S3
  # ============================================================
  collect-logs:
    needs: deploy
    runs-on: ubuntu-latest

    steps:
      - name: Install gh CLI
        run: |
          sudo apt update -y
          sudo apt install -y gh jq
          gh --version

      - name: Wait for workflow run to COMPLETE
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          RUN_ID="${{ needs.deploy.outputs.run_id }}"
          REPO="${{ github.repository }}"
          echo "Waiting for workflow run $RUN_ID to complete..."

          while true; do
            STATUS=$(gh run view "$RUN_ID" --repo "$REPO" --json status -q ".status")
            echo "Status: $STATUS"

            if [ "$STATUS" = "completed" ]; then
              echo "Run is completed!"
              break
            fi

            sleep 10
          done

      - name: Export logs into logs.txt
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          RUN_ID="${{ needs.deploy.outputs.run_id }}"
          REPO="${{ github.repository }}"

          gh run view "$RUN_ID" --repo "$REPO" --log > logs.txt
          echo "Saved logs.txt"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Upload ALL Scan Reports + logs to S3
        run: |
          RUN_ID="${{ needs.deploy.outputs.run_id }}"
          S3="s3://cf-templates-efzoo91lt857-us-east-1/security-scans/run-$RUN_ID/"

          echo "Uploading to $S3"

          aws s3 cp trufflehog-results.json "$S3"
          aws s3 cp snyk-sca.json "$S3"
          aws s3 cp snyk-sast.json "$S3"
          aws s3 cp snyk-container.json "$S3"
          aws s3 cp prisma-scan.json "$S3"
          aws s3 cp sonar-report.json "$S3"
          aws s3 cp zap-report.html "$S3"
          aws s3 cp zap-report.json "$S3"
          aws s3 cp zap-report.md "$S3"
          aws s3 cp logs.txt "$S3"

          echo "All security reports uploaded to S3."
